{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # load dataset and specify predictors/target\n",
    "# df = pd.read_csv('../data/alldata.csv', index_col='Unnamed: 0')\n",
    "# df = df[df.stop_outcome.isin([1,4])]\n",
    "# def change_1_0(x):\n",
    "#     if x == 4: return 0\n",
    "#     else: return 1\n",
    "# df.stop_outcome = df.stop_outcome.apply(lambda x: change_1_0(x))\n",
    "# predictors = df.drop(['stop_outcome'], axis = 1)\n",
    "# target = df.stop_outcome\n",
    "# target.value_counts()/len(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "X, y = load_breast_cancer(return_X_y = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data\n",
    "# X_train , X_test , y_train , y_test = train_test_split (predictors, target , test_size=0.2, random_state = 9)\n",
    "X_train , X_test , y_train , y_test = train_test_split (X, y , test_size=0.2, random_state = 9)\n",
    "# normalize data\n",
    "mms = MinMaxScaler()\n",
    "X_train = mms.fit_transform(X_train)\n",
    "X_test = mms.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train = y_train.values\n",
    "# y_test = y_test.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LogisticRegression():\n",
    "    def __init__(self, lr=0.01, num_iter=100000, fit_intercept=True, verbose=False):\n",
    "        self.lr = lr\n",
    "        self.num_iter = num_iter\n",
    "        self.fit_intercept = fit_intercept\n",
    "        self.verbose = verbose\n",
    "    \n",
    "    def __add_intercept(self, X):\n",
    "        intercept = np.ones((X.shape[0], 1))\n",
    "        return np.concatenate((intercept, X), axis=1)\n",
    "    \n",
    "    def __sigmoid(self, z):\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "    def __loss(self, h, y):\n",
    "        return (-y * np.log(h) - (1 - y) * np.log(1 - h)).mean()\n",
    "    \n",
    "    def fit(self, X, y, batch_size):\n",
    "        if self.fit_intercept:\n",
    "            X = self.__add_intercept(X)\n",
    "        \n",
    "        # weights initialization\n",
    "        self.theta = np.zeros(X.shape[1])\n",
    "        \n",
    "        for i in tqdm(range(self.num_iter)):\n",
    "            rand_indices = np.random.choice(X.shape[0], size = batch_size, replace = True)\n",
    "            X_ = X[rand_indices, :]\n",
    "            y_ = y[rand_indices]\n",
    "\n",
    "            z = np.dot(X_, self.theta)\n",
    "            h = self.__sigmoid(z)\n",
    "            gradient = np.dot(X_.T, (h - y_)) / y.size\n",
    "            self.theta -= self.lr * gradient\n",
    "            \n",
    "            if self.verbose == True and i % 1000 == 0:\n",
    "                z = np.dot(X, self.theta)\n",
    "                h = self.__sigmoid(z)\n",
    "                print(f'loss: {self.__loss(h, y)} \\t')\n",
    "    \n",
    "    def predict_prob(self, X):\n",
    "        if self.fit_intercept:\n",
    "            X = self.__add_intercept(X)\n",
    "    \n",
    "        return self.__sigmoid(np.dot(X, self.theta))\n",
    "    \n",
    "    def predict(self, X, threshold):\n",
    "        return self.predict_prob(X) >= threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f314017f6954715afc3732fe26dc0ff"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 6.19 s, sys: 86.3 ms, total: 6.28 s\n",
      "Wall time: 6.52 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9472527472527472"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression(lr=0.01, num_iter=100000, verbose=True)\n",
    "% time model.fit(X_train, y_train, batch_size=64)\n",
    "preds = model.predict(X_train, threshold = 0.5)\n",
    "# accuracy\n",
    "accuracy_score(y_train, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DPLogisticRegression():\n",
    "    def __init__(self, lr=0.01, num_iter=100000, \n",
    "                 fit_intercept=True, verbose=False,\n",
    "                 clipping_param = 5, sigma = 2,\n",
    "                 delta = 1e-6,\n",
    "                sample_with_replacement_SGD = True):\n",
    "        \n",
    "        self.lr = lr\n",
    "        self.num_iter = num_iter\n",
    "        self.fit_intercept = fit_intercept\n",
    "        self.verbose = verbose\n",
    "        self.replacement = sample_with_replacement_SGD\n",
    "        \n",
    "        # Privacy parameters\n",
    "        self.clipping_param = clipping_param\n",
    "        self.sigma = sigma\n",
    "        self.delta = delta\n",
    "        self.epsilon = None\n",
    "        \n",
    "    \n",
    "    def __add_intercept(self, X):\n",
    "        intercept = np.ones((X.shape[0], 1))\n",
    "        return np.concatenate((intercept, X), axis=1)\n",
    "    \n",
    "    def __sigmoid(self, z):\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "    def __loss(self, h, y):\n",
    "        return (-y * np.log(h) - (1 - y) * np.log(1 - h)).mean()\n",
    "\n",
    "    def __get_min_epsilon(self, batch_size, X):\n",
    "        return self.clipping_param/self.sigma*batch_size/X.shape[0]*np.sqrt(X.shape[0]//batch_size * np.log(1/self.delta))\n",
    "    \n",
    "    def fit(self, X, y, batch_size):\n",
    "        if self.fit_intercept:\n",
    "            X = self.__add_intercept(X)\n",
    "        \n",
    "        # weights initialization\n",
    "        self.theta = np.zeros(X.shape[1])\n",
    "        \n",
    "        for i in tqdm(range(self.num_iter)):\n",
    "            # fix this to not sample same row twice - or make an option\n",
    "            rand_indices = np.random.choice(X.shape[0], size = batch_size, replace = self.replacement)\n",
    "            X_ = X[rand_indices, :]\n",
    "            y_ = y[rand_indices]\n",
    "\n",
    "            z = np.dot(X_, self.theta)\n",
    "            h = self.__sigmoid(z)\n",
    "            gradient = np.dot(X_.T, (h - y_)) / y_.size\n",
    "            \n",
    "            # clip the gradient using microbatch concept - fix this by calculating gradient example by example\n",
    "            gradient_clipped = gradient/max(1, np.linalg.norm(gradient))\n",
    "            gradient_noisy = gradient_clipped + 1/y_.size * (np.random.normal(loc = 0.0, scale = self.sigma * self.clipping_param))\n",
    "            \n",
    "#             print('thetas: \\t', self.theta)\n",
    "            self.theta -= self.lr * gradient_noisy\n",
    "            \n",
    "            if self.verbose == True and i % 1000 == 0:\n",
    "                z = np.dot(X, self.theta)\n",
    "                h = self.__sigmoid(z)\n",
    "                print(f'loss: {self.__loss(h, y)} \\t')\n",
    "        \n",
    "        self.epsilon = self.__get_min_epsilon(batch_size, X)\n",
    "    \n",
    "    def predict_prob(self, X):\n",
    "        if self.fit_intercept:\n",
    "            X = self.__add_intercept(X)\n",
    "    \n",
    "        return self.__sigmoid(np.dot(X, self.theta))\n",
    "    \n",
    "    def predict(self, X, threshold):\n",
    "        return self.predict_prob(X) >= threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "717334ea9ada45418c504bd68814434c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 7.44 s, sys: 129 ms, total: 7.57 s\n",
      "Wall time: 7.73 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9252747252747253"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = DPLogisticRegression(lr=0.001, num_iter=100000, verbose=False, fit_intercept = True, \n",
    "                            clipping_param=1, sigma=2, delta=1e-2)\n",
    "% time model.fit(X_train, y_train, batch_size=1)\n",
    "preds = model.predict(X_train, threshold = 0.5)\n",
    "# accuracy\n",
    "accuracy_score(y_train, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6491228070175439"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_preds = model.predict(X_test, threshold = 0.5)\n",
    "# accuracy\n",
    "(test_preds == y_test).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0010060443904727954"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
